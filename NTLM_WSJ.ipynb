{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba0f15f-8e4d-4215-b3f2-6cb111dd326a",
   "metadata": {},
   "source": [
    "## <code>NTLM IR Experiment</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e345b44",
   "metadata": {},
   "source": [
    "### Log-Likelihood for Document Ranking and Neural Translation Model for Query Likelihood\n",
    "\n",
    "1. **Log-Likelihood for Document Ranking**:\n",
    "   - Estimates the probability of generating the query $( q )$ given a document $( d )$.\n",
    "   \n",
    "     \n",
    "      $$log p(q|d) = \\sum_{i:c(q_i;d)>0} \\log \\left( \\frac{p(q_i|d)}{\\alpha_d * p(q_i|C)} \\right) + n \\log \\alpha_d \\text{........................Eq(1) }$$\n",
    "      \n",
    "   **Where:**\n",
    "   - $p(q_i|d)$ is the probability of term \\( q_i \\) given document \\( d \\).\n",
    "   - $alpha_d$ is a normalizing factor.\n",
    "   - $p(q_i|C)$ is the probability of term \\( q_i \\) in the collection \\( C \\).\n",
    "2. **Cosine Similarity**\n",
    "    - $$ {cosine\\_similarity}(u, w) = \\frac{u \\cdot w}{|u| |w|} $$\n",
    " \n",
    "     $$p_t(w|u) = \\frac{ \\text{cos}(u', w)}{\\sum_{u_0 \\in V} \\text{cos}(u, w)}   \\text{............................................................................Eq(2) insert it into Eq(3) }$$  \n",
    "\n",
    "\n",
    "3. **Translation Model for Query Likelihood**:\n",
    "   - Models the process of query generation as a translation from document terms to query terms.\n",
    "   \n",
    "     \n",
    "     $$p_t(w|d) = \\sum_{u \\in d} p_t(w|u) p(u|d)  \\text{............................................................Eq(3) }$$ \n",
    "     \n",
    "   **Where:**\n",
    "   - $p_t(w|u)$ is the probability of translating document term $( u )$ into query term $( w )$.\n",
    "   - $p(u|d)$ is the probability of term $( u )$ occurring in document $( d )$.\n",
    "\n",
    "4. **The probability of term $u$ occurring in document $d$**\n",
    "   - $$p(u|d) = \\frac{{\\text{tf}(u, d)}}{{\\sum_{v \\in d} \\text{tf}(v, d)}} \\text{............................................................Eq(4) }$$\n",
    "\n",
    "   **Where:**\n",
    "   - $p(u|d)$ represents the probability of term $( u )$ occurring in document $( d )$.\n",
    "   - $\\text{tf}(u, d)$ denotes the frequency of term $( u )$ in document $( d )$.\n",
    "   - $\\sum_{v \\in d} \\text{tf}(v, d)$ calculates the total number of terms in document $( d )$.\n",
    "   \n",
    "   \n",
    "   \n",
    "5. **Probability of Query Term $( q_i )$ in the Collection $( C )$ ---> $p(q_i|C)$**\n",
    "\n",
    "   The probability  $p(q_i|C)$ represents the likelihood of term $(q_i)$ appearing in the entire collection of documents $(C)$. \n",
    "   It is calculated as the term frequency of $(q_i)$ in the collection $(C)$ divided by the total number of terms in the collection.\n",
    "\n",
    "   - $$p(q_i|C) = \\frac{\\text{cf}(q_i, C)}{\\sum_{v \\in C} \\text{cf}(v, C)} \\text{............................................................Eq(5) }$$\n",
    "\n",
    "   **Where:**\n",
    "   - $\\text{cf}(q_i, C)$ : Collection frequency of term $( q_i )$ in the collection $( C )$.\n",
    "   - $\\sum_{v \\in C} \\text{cf}(v, C)$: Total number of terms in the entire collection ( C )$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. **Connecting the Two Concepts**:\n",
    "   \n",
    "   - Specifically, $ p(q_i|d) $ can be estimated using $ p_t(w|d) $:\n",
    "   \n",
    "     $p_t(w|d) \\approx p_t(q_i|d)$\n",
    "     \n",
    "     $p(u|d)$\n",
    "     \n",
    "     $p(q_i|C)$\n",
    "     \n",
    "   - Substitute these equations in $Eq (1)$\n",
    "\n",
    "7. **Final Log-Likelihood for Document Ranking Equation Eq(1)**:\n",
    "   - Using the Neural translation model, the log-likelihood equation becomes:\n",
    "     \n",
    "     $$log p(q|d) = \\sum_{i:c(q_i;d)>0} \\log \\left( \\frac{\\sum_{u \\in d} p_t(q_i|u) p(u|d)}{\\alpha_d * p(q_i|C)} \\right) + n \\log \\alpha_d$$\n",
    "     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e0c17a-fdc0-4efe-aa7b-f508fea422db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:33.436638Z",
     "start_time": "2024-06-10T09:33:33.431372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dolla\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "#import scipy\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pyterrier as pt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43879c",
   "metadata": {},
   "source": [
    "### Setup java environment for pyterrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4583629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:34.336654Z",
     "start_time": "2024-06-10T09:33:34.330001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME set to: C:\\Program Files\\Java\\jdk-11\n"
     ]
    }
   ],
   "source": [
    "# Set JAVA_HOME environment variable\n",
    "java_home = r\"C:\\Program Files\\Java\\jdk-11\"   # adjust your java JDK folder \n",
    "\n",
    "# Verify that JAVA_HOME is set correctly\n",
    "print(\"JAVA_HOME set to:\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d1b451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:34.979599Z",
     "start_time": "2024-06-10T09:33:34.885890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 173252\n",
      "Number of terms: 176210\n",
      "Number of postings: 29484536\n",
      "Number of fields: 0\n",
      "Number of tokens: 49044405\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the relative paths based on the notebook's location\n",
    "#DISK45_PATH = os.path.join(\"concatenated_WSJ\")\n",
    "#INDEX_DIR = os.path.join(\"index_WSJ\")\n",
    "DISK45_PATH = os.path.abspath(os.path.join(\"concatenated_WSJ\"))\n",
    "INDEX_DIR = os.path.abspath(os.path.join(\"index_WSJ\"))\n",
    "\n",
    "\n",
    "# Check if the index exists\n",
    "if os.path.exists(os.path.join(INDEX_DIR, \"data.properties\")):\n",
    "    indexref = pt.IndexRef.of(os.path.join(INDEX_DIR, \"data.properties\"))\n",
    "else:    \n",
    "    # Find files in the directory\n",
    "    files = pt.io.find_files(DISK45_PATH)\n",
    "    \n",
    "    # Remove unwanted files\n",
    "    bad = ['/CR/', '/AUX/', 'READCHG', 'READMEFB', 'READFRCG', 'READMEFR', 'READMEFT', 'READMELA']\n",
    "    for b in bad:\n",
    "        files = list(filter(lambda f: b not in f, files))\n",
    "    \n",
    "    # Check if files list is empty and raise an error if it is\n",
    "    if not files:\n",
    "        raise ValueError(f\"No files found in the directory {DISK45_PATH}\")\n",
    "    \n",
    "    # Index the remaining files\n",
    "    indexer = pt.TRECCollectionIndexer(INDEX_DIR, verbose=True)\n",
    "    indexref = indexer.index(files)\n",
    "\n",
    "# Create an index object\n",
    "index = pt.IndexFactory.of(indexref)\n",
    "\n",
    "# collection statistics\n",
    "print(index.getCollectionStatistics().toString())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37967072-86dd-4463-b363-d4927841aa6f",
   "metadata": {},
   "source": [
    "## Loading the AP Topics & qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ad82fa7-400c-4ee7-bc67-ea7338055854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:36.603910Z",
     "start_time": "2024-06-10T09:33:36.529773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:02:09.932 [main] WARN org.terrier.applications.batchquerying.TRECQuery -- trec.encoding is not set; resorting to platform default (windows-1252). Retrieval may be platform dependent. Recommend trec.encoding=UTF-8\n"
     ]
    }
   ],
   "source": [
    "# Define the relative paths based on the notebook's location\n",
    "\n",
    "topics_path = os.path.join(\"topics\",\"all_topics_fixed.txt\")\n",
    "qrels_path = os.path.join(\"qrels\",\"WSJ_only.txt\")\n",
    "#index_path = os.path.join(\"..\", \"Data\", \"WSJ_Doc\", \"wsj\", \"index_WSJ\")\n",
    "\n",
    "# Load topics and qrels from text files\n",
    "topics = pt.io.read_topics(topics_path)\n",
    "qrels = pt.io.read_qrels(qrels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46c158cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:37.429338Z",
     "start_time": "2024-06-10T09:33:37.407558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861203-0077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861204-0160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861204-0167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861209-0043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861209-0128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104283</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920316-0108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104284</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920317-0087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104285</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920319-0108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104286</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920323-0193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104287</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920324-0109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid           docno  label\n",
       "0        51  WSJ861203-0077      0\n",
       "1        51  WSJ861204-0160      0\n",
       "2        51  WSJ861204-0167      0\n",
       "3        51  WSJ861209-0043      0\n",
       "4        51  WSJ861209-0128      0\n",
       "...     ...             ...    ...\n",
       "104283  200  WSJ920316-0108      0\n",
       "104284  200  WSJ920317-0087      0\n",
       "104285  200  WSJ920319-0108      0\n",
       "104286  200  WSJ920323-0193      0\n",
       "104287  200  WSJ920324-0109      0\n",
       "\n",
       "[104288 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d85fc6956f5667d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:37.641983Z",
     "start_time": "2024-06-10T09:33:37.638755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>south african sanctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>leveraged buyouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>satellite launch contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>insider trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>196</td>\n",
       "      <td>school choice voucher system and its effects u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>197</td>\n",
       "      <td>reform of the jurisprudence system to stop jur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>198</td>\n",
       "      <td>gene therapy and its benefits to humankind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>199</td>\n",
       "      <td>legality of medically assisted suicides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>200</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                              query\n",
       "0     51                                   airbus subsidies\n",
       "1     52                            south african sanctions\n",
       "2     53                                  leveraged buyouts\n",
       "3     54                         satellite launch contracts\n",
       "4     55                                    insider trading\n",
       "..   ...                                                ...\n",
       "145  196  school choice voucher system and its effects u...\n",
       "146  197  reform of the jurisprudence system to stop jur...\n",
       "147  198         gene therapy and its benefits to humankind\n",
       "148  199            legality of medically assisted suicides\n",
       "149  200  impact of foreign textile imports on u s texti...\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641090b6",
   "metadata": {},
   "source": [
    "### preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fed9d4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:46.295242Z",
     "start_time": "2024-06-10T09:33:38.366637Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_trec_file(trec_file_path):\n",
    "    doc_texts = {}\n",
    "    current_doc_id = None\n",
    "    current_text = []\n",
    "    \n",
    "    encodings = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(trec_file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('<DOCNO>'):\n",
    "                        current_doc_id = line.strip().replace('<DOCNO>', '').replace('</DOCNO>', '').strip()\n",
    "                    elif line.startswith('</TEXT>'):\n",
    "                        if current_doc_id:\n",
    "                            doc_texts[current_doc_id] = ' '.join(current_text)\n",
    "                            current_doc_id = None\n",
    "                            current_text = []\n",
    "                    elif current_doc_id:\n",
    "                        if not (line.startswith('<DOC>') or line.startswith('</DOC>') or line.startswith('<FILEID>') or\n",
    "                                line.startswith('<FIRST>') or line.startswith('<SECOND>') or line.startswith('<HEAD>') or\n",
    "                                line.startswith('<DATELINE>') or line.startswith('<TEXT>') or \n",
    "                                line.startswith('<HL>') or line.startswith('</HL>') or \n",
    "                                line.startswith('<DD>') or line.startswith('</DD>') or \n",
    "                                line.startswith('<SO>') or line.startswith('</SO>') or \n",
    "                                line.startswith('<IN>') or line.startswith('</IN>')):\n",
    "                            current_text.append(line.strip())\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue  \n",
    "\n",
    "    return doc_texts\n",
    "\n",
    "# Path to your concatenated TREC file\n",
    "trec_file_path = os.path.join(\"concatenated_WSJ\",\"concatenated_WSJ.txt\")\n",
    "\n",
    "\n",
    "# Parse the document texts\n",
    "doc_texts = parse_trec_file(trec_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2be07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(list(doc_texts.items())[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d87abd",
   "metadata": {},
   "source": [
    "#### Inital ranking using Dirichlet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54878e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(DirichletLM): 100%|██████████| 150/150 [00:04<00:00, 36.05q/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>27745</td>\n",
       "      <td>WSJ871218-0126</td>\n",
       "      <td>0</td>\n",
       "      <td>13.950991</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>111455</td>\n",
       "      <td>WSJ900720-0157</td>\n",
       "      <td>1</td>\n",
       "      <td>13.266061</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>1016</td>\n",
       "      <td>WSJ870316-0068</td>\n",
       "      <td>2</td>\n",
       "      <td>12.942354</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>77369</td>\n",
       "      <td>WSJ880315-0169</td>\n",
       "      <td>3</td>\n",
       "      <td>12.656361</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>164736</td>\n",
       "      <td>WSJ920116-0130</td>\n",
       "      <td>4</td>\n",
       "      <td>12.501765</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146857</th>\n",
       "      <td>200</td>\n",
       "      <td>104584</td>\n",
       "      <td>WSJ900518-0081</td>\n",
       "      <td>995</td>\n",
       "      <td>4.564010</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146858</th>\n",
       "      <td>200</td>\n",
       "      <td>35189</td>\n",
       "      <td>WSJ870717-0014</td>\n",
       "      <td>996</td>\n",
       "      <td>4.563954</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146859</th>\n",
       "      <td>200</td>\n",
       "      <td>51240</td>\n",
       "      <td>WSJ881013-0006</td>\n",
       "      <td>997</td>\n",
       "      <td>4.561225</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860</th>\n",
       "      <td>200</td>\n",
       "      <td>40472</td>\n",
       "      <td>WSJ871111-0099</td>\n",
       "      <td>998</td>\n",
       "      <td>4.559232</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146861</th>\n",
       "      <td>200</td>\n",
       "      <td>168539</td>\n",
       "      <td>WSJ920214-0152</td>\n",
       "      <td>999</td>\n",
       "      <td>4.558956</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146862 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid   docid           docno  rank      score  \\\n",
       "0        51   27745  WSJ871218-0126     0  13.950991   \n",
       "1        51  111455  WSJ900720-0157     1  13.266061   \n",
       "2        51    1016  WSJ870316-0068     2  12.942354   \n",
       "3        51   77369  WSJ880315-0169     3  12.656361   \n",
       "4        51  164736  WSJ920116-0130     4  12.501765   \n",
       "...     ...     ...             ...   ...        ...   \n",
       "146857  200  104584  WSJ900518-0081   995   4.564010   \n",
       "146858  200   35189  WSJ870717-0014   996   4.563954   \n",
       "146859  200   51240  WSJ881013-0006   997   4.561225   \n",
       "146860  200   40472  WSJ871111-0099   998   4.559232   \n",
       "146861  200  168539  WSJ920214-0152   999   4.558956   \n",
       "\n",
       "                                                    query  \n",
       "0                                        airbus subsidies  \n",
       "1                                        airbus subsidies  \n",
       "2                                        airbus subsidies  \n",
       "3                                        airbus subsidies  \n",
       "4                                        airbus subsidies  \n",
       "...                                                   ...  \n",
       "146857  impact of foreign textile imports on u s texti...  \n",
       "146858  impact of foreign textile imports on u s texti...  \n",
       "146859  impact of foreign textile imports on u s texti...  \n",
       "146860  impact of foreign textile imports on u s texti...  \n",
       "146861  impact of foreign textile imports on u s texti...  \n",
       "\n",
       "[146862 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet = pt.BatchRetrieve(index, wmodel=\"DirichletLM\", controls={'dirichletlm.mu': 1500}, verbose=True) \n",
    "retrieved_results = dirichlet.transform(topics)\n",
    "retrieved_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fabab",
   "metadata": {},
   "source": [
    "#### Loading Word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db476912-1b42-406e-a72a-f887e97ab337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:47.167619Z",
     "start_time": "2024-06-10T09:33:46.296738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained word embeddings\n",
    "\n",
    "word_embeddings_path = r\"GoogleNews-vectors-negative300-SLIM.bin\"   \n",
    "word_embeddings = gensim.models.KeyedVectors.load_word2vec_format(word_embeddings_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238b8c1",
   "metadata": {},
   "source": [
    "### Implementation of reranking with NTLM using Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9709c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(DirichletLM): 100%|██████████| 150/150 [00:06<00:00, 22.25q/s]\n",
      "Processing Topics: 100%|██████████| 150/150 [1:30:35<00:00, 36.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pyterrier as pt\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate term frequencies for documents and collection\n",
    "def calculate_term_frequencies(doc_texts):\n",
    "    term_frequencies = {}\n",
    "    collection_frequencies = defaultdict(int)\n",
    "    total_terms_in_collection = 0\n",
    "    \n",
    "    for doc_id, text in doc_texts.items():\n",
    "        term_freq = defaultdict(int)\n",
    "        document_terms = text.split()  # Split text into terms\n",
    "        total_terms_in_doc = len(document_terms)\n",
    "        \n",
    "        for term in document_terms:\n",
    "            term_freq[term] += 1\n",
    "            collection_frequencies[term] += 1\n",
    "            total_terms_in_collection += 1\n",
    "        \n",
    "        term_frequencies[doc_id] = (term_freq, total_terms_in_doc)\n",
    "    \n",
    "    return term_frequencies, collection_frequencies, total_terms_in_collection\n",
    "\n",
    "# Function to calculate the probability of term u given document d\n",
    "def p_u_given_d(term, doc_term_freq, total_terms_in_doc):\n",
    "    return doc_term_freq[term] / total_terms_in_doc if total_terms_in_doc > 0 else 0\n",
    "\n",
    "# Function to calculate the probability of term u in the collection C\n",
    "def p_u_given_C(term, collection_frequencies, total_terms_in_collection):\n",
    "    return collection_frequencies[term] / total_terms_in_collection if total_terms_in_collection > 0 else 0\n",
    "\n",
    "# Compute cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Compute translation probability using cosine similarity\n",
    "def compute_translation_probability(target_word, candidate_term, word_embeddings):\n",
    "    if target_word in word_embeddings and candidate_term in word_embeddings:\n",
    "        target_vector = word_embeddings[target_word]\n",
    "        candidate_vector = word_embeddings[candidate_term]\n",
    "        # Normalize cosine similarity to [0, 1]\n",
    "        return (cosine_similarity(target_vector, candidate_vector)+1)/2 \n",
    "    else:\n",
    "        return 0.0 \n",
    "\n",
    "# Compute log-likelihood ratio\n",
    "def compute_log_likelihood_ratio(translation_prob, p_qi_C, alpha, n):\n",
    "    return (np.log(translation_prob / (p_qi_C * alpha)) + n * np.log(alpha))\n",
    "\n",
    "# Score documents based on translation probabilities\n",
    "def score_document(query, document, word_embeddings, doc_term_freq, total_terms_in_doc, collection_frequencies, total_terms_in_collection, alpha=0.7):\n",
    "    score = 0.0\n",
    "    n = len(query)\n",
    "\n",
    "    for query_term in query:\n",
    "        if query_term not in word_embeddings:\n",
    "            continue  # Skip query terms not in word embeddings\n",
    "\n",
    "        translation_prob_sum = 0.0\n",
    "\n",
    "        for doc_term in document:\n",
    "            if doc_term not in word_embeddings:\n",
    "                continue  # Skip document terms not in word embeddings\n",
    "\n",
    "            p_qi_d = p_u_given_d(query_term, doc_term_freq, total_terms_in_doc) # ....................................Eq(4)\n",
    "            p_qi_C = p_u_given_C(query_term, collection_frequencies, total_terms_in_collection) #.....................Eq(5)\n",
    "            translation_prob = compute_translation_probability(query_term, doc_term, word_embeddings)\n",
    "            translation_prob_sum += (translation_prob * p_qi_d)  # ........................................................Eq(3)\n",
    "        \n",
    "        if translation_prob_sum > 0:\n",
    "            log_likelihood_ratio = compute_log_likelihood_ratio(translation_prob_sum, p_qi_C, alpha, n) # ..................Eq(1)\n",
    "            score += log_likelihood_ratio\n",
    "\n",
    "    return score\n",
    "\n",
    "dirichlet = pt.BatchRetrieve(index, wmodel=\"DirichletLM\", controls={'dirichletlm.mu': 1500}, verbose=True)\n",
    "\n",
    "# Retrieve and rank documents\n",
    "def retrieve_and_rank_documents(doc_texts, topics, word_embeddings, alpha=0.7):\n",
    "    results = []\n",
    "    \n",
    "    # Calculate term frequencies for documents and collection\n",
    "    term_frequencies, collection_frequencies, total_terms_in_collection = calculate_term_frequencies(doc_texts)\n",
    "    \n",
    "    # Retrieve initial set of documents using Dirichlet language model\n",
    "    result = dirichlet.transform(topics)\n",
    "    \n",
    "    for idx, row in tqdm(topics.iterrows(), total=len(topics), desc=\"Processing Topics\", position=0, leave=True):\n",
    "        topic_id = row['qid']\n",
    "        query = row['query'].split()\n",
    "        scores = []\n",
    "        \n",
    "        retrieved_docs = result.loc[result[\"qid\"] == topic_id]['docno'].values\n",
    "        \n",
    "        # Iterate over all document IDs in the topics\n",
    "        for doc_id in doc_texts.keys():\n",
    "            if doc_id not in retrieved_docs:\n",
    "                continue\n",
    "            doc_text = doc_texts[doc_id]\n",
    "            doc_terms = doc_text.split()\n",
    "            doc_term_freq, total_terms_in_doc = term_frequencies[doc_id]\n",
    "            score = score_document(query, doc_terms, word_embeddings, doc_term_freq, total_terms_in_doc, collection_frequencies, total_terms_in_collection, alpha)\n",
    "            scores.append((doc_id, score))\n",
    "        \n",
    "        ranked_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        for rank, (doc_id, score) in enumerate(ranked_scores):\n",
    "            results.append({\n",
    "                'qid': topic_id,\n",
    "                'docno': doc_id,\n",
    "                'rank': rank + 1,\n",
    "                'score': score,\n",
    "                'query': ' '.join(query)\n",
    "            })\n",
    "    return pd.DataFrame(results, columns=['qid', 'docno', 'rank', 'score', 'query'])\n",
    "\n",
    "retrieved_results = retrieve_and_rank_documents(doc_texts, topics, word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607c800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8131bdb",
   "metadata": {},
   "source": [
    "#### Save the reranked result \"retrieved_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d423906",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"result_files\",\"reranked_retrieved_results.csv\")\n",
    "\n",
    "retrieved_results.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983566f",
   "metadata": {},
   "source": [
    "### Evaluation the reranked result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35eb1836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dolla\\AppData\\Local\\Temp\\ipykernel_16900\\131452853.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "================================================================================\n",
      "              Model                             File      MAP     P@10\n",
      "Dirichlet model WSJ WSJ_Dirichlet_ranked_results.csv 0.273027 0.448667\n",
      "           NTLM WSJ   reranked_retrieved_results.csv 0.087345 0.253333\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytrec_eval\n",
    "import os\n",
    "\n",
    "# Define reranked files, qrel files, and model names\n",
    "reranked_files = [\n",
    "    \n",
    "    {\"path\": os.path.join(\"result_files\",\"WSJ_Dirichlet_ranked_results.csv\"), \"qrel\": os.path.join(\"result_files\",\"WSJ_qrels.csv\"), \"model\": \"Dirichlet model WSJ\"},  # dirichlet model\n",
    "\n",
    "    {\"path\": os.path.join(\"result_files\",\"reranked_retrieved_results.csv\"), \"qrel\": os.path.join(\"result_files\",\"WSJ_qrels.csv\"), \"model\": \"NTLM WSJ\"}, # reranking using NTLM\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "def evaluate_reranked_results(reranked_df, qrel_df):\n",
    "    qrels = {str(qid): {str(docno): int(label) for docno, label in zip(qrel_df.loc[qrel_df['qid'] == qid, 'docno'], qrel_df.loc[qrel_df['qid'] == qid, 'label'])} for qid in qrel_df['qid'].unique()}\n",
    "    results = {str(qid): {str(docno): float(score) for docno, score in zip(reranked_df.loc[reranked_df['qid'] == qid, 'docno'], reranked_df.loc[reranked_df['qid'] == qid, 'score'])} for qid in reranked_df['qid'].unique()}\n",
    "\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'P_10', \"ndcg\"})\n",
    "    metrics = evaluator.evaluate(results)\n",
    "\n",
    "    map_score = sum([m['map'] for m in metrics.values()]) / len(metrics)\n",
    "    p10_score = sum([m['P_10'] for m in metrics.values()]) / len(metrics)\n",
    "    \n",
    "    return map_score, p10_score\n",
    "\n",
    "# DataFrame to store evaluation results\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"File\", \"MAP\", \"P@10\"])\n",
    "\n",
    "# Loop through reranked files and evaluate them\n",
    "for file_info in reranked_files:\n",
    "    try:\n",
    "        reranked_df = pd.read_csv(file_info[\"path\"])\n",
    "        qrel_df = pd.read_csv(file_info[\"qrel\"])\n",
    "\n",
    "        map_score, p10_score = evaluate_reranked_results(reranked_df, qrel_df)\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Model\": [file_info[\"model\"]],\n",
    "            \"File\": [os.path.basename(file_info[\"path\"])],\n",
    "            \"MAP\": [map_score],\n",
    "            \"P@10\": [p10_score]\n",
    "        })\n",
    "\n",
    "        results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_info['path']}: {str(e)}\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "#output_file = \"evaluation_results.csv\"\n",
    "#results_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "print(\"=\" * 80)\n",
    "#print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ee416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
